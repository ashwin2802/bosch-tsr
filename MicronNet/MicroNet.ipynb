{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "nclasses = 43 # GTSRB as 43 classes\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 1, kernel_size=1)\n",
    "        self.conv2 = nn.Conv2d(1, 29, kernel_size=5)\n",
    "        self.maxpool2 = nn.MaxPool2d(3, stride=2 , ceil_mode=True)\n",
    "        self.conv3 = nn.Conv2d(29, 59, kernel_size=3)\n",
    "        self.maxpool3 = nn.MaxPool2d(3, stride=2 , ceil_mode=True)\n",
    "        self.conv4 = nn.Conv2d(59, 74, kernel_size=3)\n",
    "        self.maxpool4 = nn.MaxPool2d(3, stride=2 , ceil_mode=True)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.conv3_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(1184, 300)\n",
    "        self.fc2 = nn.Linear(300, nclasses)\n",
    "        self.conv0_bn = nn.BatchNorm2d(3)\n",
    "        self.conv1_bn = nn.BatchNorm2d(1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(29)\n",
    "        self.conv3_bn = nn.BatchNorm2d(59)\n",
    "        self.conv4_bn = nn.BatchNorm2d(74)\n",
    "        self.dense1_bn = nn.BatchNorm1d(300)\n",
    "    def forward(self, x):\n",
    "        x =  F.relu(self.conv1_bn(self.conv1(self.conv0_bn(x))))\n",
    "        x = F.relu(self.conv2_bn(self.conv2(x)))\n",
    "        x = F.relu(self.conv3_bn(self.conv3( self.maxpool2(x))))\n",
    "        x = F.relu(self.conv4_bn(self.conv4( self.maxpool3(x))))\n",
    "        x = self.maxpool4(x)        \n",
    "        x = x.view(-1, 1184)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dense1_bn(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        return F.log_softmax(x)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "\n",
    "batch_size =50                                                                                                                                                                                     \n",
    "epochs = 10000                                                                                                                                                                                                                                                                                                                                                                                 \n",
    "seed = 1                                                                                                                                                                                           \n",
    "log_interval=180                                                                                                                                                                                   \n",
    "data = \"Dataset\"                                                                                                                                                                                                                                                                                                                                                                                          \n",
    "torch.manual_seed(1)                                                                                                                                                                               \n",
    "lr =0.007                                                                                                                                                                                          \n",
    "momentum = 0.8                                                                                                                                                                                     \n",
    "decay = 0.9                                                                                                                                                                                        \n",
    "step = 1000                                                                                                                                                                                        \n",
    "l2_norm = 0.00001  \n",
    "cuda = True\n",
    "resume = False\n",
    "# These may change as described in paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ADataset(Dataset):\n",
    "    def __init__(self, images_filepaths, transform=None):\n",
    "        self.images_filepaths = images_filepaths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_filepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.images_filepaths[idx]\n",
    "        image = cv2.imread(image_filepath)\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        label = int(os.path.normpath(image_filepath).split(os.sep)[-2])\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image=image)[\"image\"]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset/val_images\n",
      "35339\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "from data import initialize_data, data_transforms \n",
    "initialize_data(\"Dataset\") # extracts the zip files, makes a validation set\n",
    "\n",
    "# train_loader = DataLoader(\n",
    "#     datasets.ImageFolder(data + '/train_images',\n",
    "#                          transform=data_transforms),\n",
    "#     batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "\n",
    "def generateImgFilePaths(base_path):\n",
    "    imgpths = []\n",
    "    for i in range(nclasses):\n",
    "        fldr=(\"/0000\" if i<10 else \"/000\")+str(i)\n",
    "        for path in os.listdir(base_path+fldr):\n",
    "            full_path = os.path.join(base_path+fldr, path)\n",
    "            if os.path.isfile(full_path) and not full_path.endswith(\".csv\"):\n",
    "                imgpths.append(full_path)\n",
    "    return imgpths\n",
    "\n",
    "print(len(generateImgFilePaths(data + '/train_images')))\n",
    "\n",
    "fxc = ADataset(images_filepaths=generateImgFilePaths(data + '/train_images'), transform=data_transforms)\n",
    "train_loader = DataLoader(fxc, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "\n",
    "fxv = ADataset(images_filepaths=generateImgFilePaths(data + '/val_images'), transform=data_transforms)\n",
    "val_loader = DataLoader(fxv, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "# val_loader = DataLoader(\n",
    "#     datasets.ImageFolder(data + '/val_images',\n",
    "#                          transform=data_transforms),\n",
    "#     batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = Net()\n",
    "if  cuda: \n",
    "    model.to(device)\n",
    "\n",
    "if resume :\n",
    "    state_dict = torch.load(\"model_78.pth\")\n",
    "    model.load_state_dict(state_dict) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation():\n",
    "    model.eval()\n",
    "    validation_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in val_loader:\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        data=data.float()\n",
    "        data =data.to(device)\n",
    "        target =target.to(device)\n",
    "        output = model(data)\n",
    "        validation_loss += F.nll_loss(output, target, size_average=False).data.item() # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "    validation_loss /= len(val_loader.dataset)\n",
    "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        validation_loss, correct, len(val_loader.dataset),\n",
    "        100. * correct / len(val_loader.dataset)))\n",
    "    return validation_loss\n",
    "\n",
    "\n",
    "def train(epoch , train_loader):\n",
    "#     model.float()\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        data=data.float()\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target).cuda()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, batch_idx * len(data), len(train_loader.dataset),100. * batch_idx / len(train_loader), loss.data.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-493c3bbaedf2>:39: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/35339 (0%)]\tLoss: 4.791858\n",
      "Train Epoch: 1 [9000/35339 (25%)]\tLoss: 3.335840\n",
      "Train Epoch: 1 [18000/35339 (51%)]\tLoss: 2.782558\n",
      "Train Epoch: 1 [27000/35339 (76%)]\tLoss: 2.660691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\utkarsh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\nn\\_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation set: Average loss: 2.6919, Accuracy: 1465/3870 (38%)\n",
      "\n",
      "\n",
      "Saved model to model_1.pth. You can run `python evaluate.py model_1.pth` to generate the Kaggle formatted csv file\n",
      "Train Epoch: 2 [0/35339 (0%)]\tLoss: 2.790171\n",
      "Train Epoch: 2 [9000/35339 (25%)]\tLoss: 2.440998\n",
      "Train Epoch: 2 [18000/35339 (51%)]\tLoss: 2.350769\n",
      "Train Epoch: 2 [27000/35339 (76%)]\tLoss: 2.349819\n",
      "\n",
      "Validation set: Average loss: 2.0276, Accuracy: 2349/3870 (61%)\n",
      "\n",
      "\n",
      "Saved model to model_2.pth. You can run `python evaluate.py model_2.pth` to generate the Kaggle formatted csv file\n",
      "Train Epoch: 3 [0/35339 (0%)]\tLoss: 2.079546\n",
      "Train Epoch: 3 [9000/35339 (25%)]\tLoss: 2.317107\n",
      "Train Epoch: 3 [18000/35339 (51%)]\tLoss: 2.041207\n",
      "Train Epoch: 3 [27000/35339 (76%)]\tLoss: 2.085842\n",
      "\n",
      "Validation set: Average loss: 1.4350, Accuracy: 2951/3870 (76%)\n",
      "\n",
      "\n",
      "Saved model to model_3.pth. You can run `python evaluate.py model_3.pth` to generate the Kaggle formatted csv file\n",
      "Train Epoch: 4 [0/35339 (0%)]\tLoss: 1.998011\n",
      "Train Epoch: 4 [9000/35339 (25%)]\tLoss: 2.108701\n",
      "Train Epoch: 4 [18000/35339 (51%)]\tLoss: 1.768286\n",
      "Train Epoch: 4 [27000/35339 (76%)]\tLoss: 1.802470\n",
      "\n",
      "Validation set: Average loss: 1.2872, Accuracy: 3060/3870 (79%)\n",
      "\n",
      "\n",
      "Saved model to model_4.pth. You can run `python evaluate.py model_4.pth` to generate the Kaggle formatted csv file\n",
      "Train Epoch: 5 [0/35339 (0%)]\tLoss: 2.020596\n",
      "Train Epoch: 5 [9000/35339 (25%)]\tLoss: 2.027088\n",
      "Train Epoch: 5 [18000/35339 (51%)]\tLoss: 1.885906\n",
      "Train Epoch: 5 [27000/35339 (76%)]\tLoss: 1.977505\n",
      "\n",
      "Validation set: Average loss: 1.1568, Accuracy: 3141/3870 (81%)\n",
      "\n",
      "\n",
      "Saved model to model_5.pth. You can run `python evaluate.py model_5.pth` to generate the Kaggle formatted csv file\n",
      "Train Epoch: 6 [0/35339 (0%)]\tLoss: 1.647663\n",
      "Train Epoch: 6 [9000/35339 (25%)]\tLoss: 2.212619\n",
      "Train Epoch: 6 [18000/35339 (51%)]\tLoss: 2.146709\n",
      "Train Epoch: 6 [27000/35339 (76%)]\tLoss: 1.849282\n",
      "\n",
      "Validation set: Average loss: 1.1070, Accuracy: 3157/3870 (82%)\n",
      "\n",
      "\n",
      "Saved model to model_6.pth. You can run `python evaluate.py model_6.pth` to generate the Kaggle formatted csv file\n",
      "Train Epoch: 7 [0/35339 (0%)]\tLoss: 1.752447\n",
      "Train Epoch: 7 [9000/35339 (25%)]\tLoss: 2.092158\n",
      "Train Epoch: 7 [18000/35339 (51%)]\tLoss: 2.204846\n",
      "Train Epoch: 7 [27000/35339 (76%)]\tLoss: 1.628519\n",
      "\n",
      "Validation set: Average loss: 0.9844, Accuracy: 3274/3870 (85%)\n",
      "\n",
      "\n",
      "Saved model to model_7.pth. You can run `python evaluate.py model_7.pth` to generate the Kaggle formatted csv file\n",
      "Train Epoch: 8 [0/35339 (0%)]\tLoss: 1.924958\n",
      "Train Epoch: 8 [9000/35339 (25%)]\tLoss: 2.291402\n",
      "Train Epoch: 8 [18000/35339 (51%)]\tLoss: 1.825989\n",
      "Train Epoch: 8 [27000/35339 (76%)]\tLoss: 1.869657\n",
      "\n",
      "Validation set: Average loss: 0.8457, Accuracy: 3338/3870 (86%)\n",
      "\n",
      "\n",
      "Saved model to model_8.pth. You can run `python evaluate.py model_8.pth` to generate the Kaggle formatted csv file\n",
      "Train Epoch: 9 [0/35339 (0%)]\tLoss: 1.607984\n",
      "Train Epoch: 9 [9000/35339 (25%)]\tLoss: 1.719016\n",
      "Train Epoch: 9 [18000/35339 (51%)]\tLoss: 1.834338\n",
      "Train Epoch: 9 [27000/35339 (76%)]\tLoss: 1.952498\n",
      "\n",
      "Validation set: Average loss: 0.8302, Accuracy: 3312/3870 (86%)\n",
      "\n",
      "\n",
      "Saved model to model_9.pth. You can run `python evaluate.py model_9.pth` to generate the Kaggle formatted csv file\n",
      "Train Epoch: 10 [0/35339 (0%)]\tLoss: 1.513805\n",
      "Train Epoch: 10 [9000/35339 (25%)]\tLoss: 1.986185\n",
      "Train Epoch: 10 [18000/35339 (51%)]\tLoss: 1.151108\n",
      "Train Epoch: 10 [27000/35339 (76%)]\tLoss: 2.287835\n",
      "\n",
      "Validation set: Average loss: 0.7555, Accuracy: 3363/3870 (87%)\n",
      "\n",
      "\n",
      "Saved model to model_10.pth. You can run `python evaluate.py model_10.pth` to generate the Kaggle formatted csv file\n",
      "Train Epoch: 11 [0/35339 (0%)]\tLoss: 1.731633\n",
      "Train Epoch: 11 [9000/35339 (25%)]\tLoss: 1.705652\n",
      "Train Epoch: 11 [18000/35339 (51%)]\tLoss: 1.854632\n",
      "Train Epoch: 11 [27000/35339 (76%)]\tLoss: 1.708656\n",
      "\n",
      "Validation set: Average loss: 0.7359, Accuracy: 3368/3870 (87%)\n",
      "\n",
      "\n",
      "Saved model to model_11.pth. You can run `python evaluate.py model_11.pth` to generate the Kaggle formatted csv file\n",
      "Train Epoch: 12 [0/35339 (0%)]\tLoss: 2.150320\n",
      "Train Epoch: 12 [9000/35339 (25%)]\tLoss: 1.697255\n",
      "Train Epoch: 12 [18000/35339 (51%)]\tLoss: 1.879988\n",
      "Train Epoch: 12 [27000/35339 (76%)]\tLoss: 2.061870\n",
      "\n",
      "Validation set: Average loss: 0.7144, Accuracy: 3397/3870 (88%)\n",
      "\n",
      "\n",
      "Saved model to model_12.pth. You can run `python evaluate.py model_12.pth` to generate the Kaggle formatted csv file\n",
      "Train Epoch: 13 [0/35339 (0%)]\tLoss: 1.786976\n",
      "Train Epoch: 13 [9000/35339 (25%)]\tLoss: 1.917519\n",
      "Train Epoch: 13 [18000/35339 (51%)]\tLoss: 1.459214\n",
      "Train Epoch: 13 [27000/35339 (76%)]\tLoss: 1.677583\n",
      "\n",
      "Validation set: Average loss: 0.7237, Accuracy: 3386/3870 (87%)\n",
      "\n",
      "Train Epoch: 14 [0/35339 (0%)]\tLoss: 1.726062\n",
      "Train Epoch: 14 [9000/35339 (25%)]\tLoss: 2.244303\n",
      "Train Epoch: 14 [18000/35339 (51%)]\tLoss: 1.719786\n",
      "Train Epoch: 14 [27000/35339 (76%)]\tLoss: 2.039322\n",
      "\n",
      "Validation set: Average loss: 0.6722, Accuracy: 3445/3870 (89%)\n",
      "\n",
      "\n",
      "Saved model to model_14.pth. You can run `python evaluate.py model_14.pth` to generate the Kaggle formatted csv file\n",
      "Train Epoch: 15 [0/35339 (0%)]\tLoss: 1.566276\n",
      "Train Epoch: 15 [9000/35339 (25%)]\tLoss: 2.132374\n",
      "Train Epoch: 15 [18000/35339 (51%)]\tLoss: 1.415414\n",
      "Train Epoch: 15 [27000/35339 (76%)]\tLoss: 1.452554\n",
      "\n",
      "Validation set: Average loss: 0.6750, Accuracy: 3437/3870 (89%)\n",
      "\n",
      "Train Epoch: 16 [0/35339 (0%)]\tLoss: 1.694042\n",
      "Train Epoch: 16 [9000/35339 (25%)]\tLoss: 1.400284\n",
      "Train Epoch: 16 [18000/35339 (51%)]\tLoss: 1.876821\n",
      "Train Epoch: 16 [27000/35339 (76%)]\tLoss: 1.518992\n",
      "\n",
      "Validation set: Average loss: 0.6546, Accuracy: 3428/3870 (89%)\n",
      "\n",
      "\n",
      "Saved model to model_16.pth. You can run `python evaluate.py model_16.pth` to generate the Kaggle formatted csv file\n",
      "Train Epoch: 17 [0/35339 (0%)]\tLoss: 1.469062\n",
      "Train Epoch: 17 [9000/35339 (25%)]\tLoss: 1.910227\n",
      "Train Epoch: 17 [18000/35339 (51%)]\tLoss: 1.741983\n",
      "Train Epoch: 17 [27000/35339 (76%)]\tLoss: 1.920334\n",
      "\n",
      "Validation set: Average loss: 0.6193, Accuracy: 3430/3870 (89%)\n",
      "\n",
      "\n",
      "Saved model to model_17.pth. You can run `python evaluate.py model_17.pth` to generate the Kaggle formatted csv file\n",
      "Train Epoch: 18 [0/35339 (0%)]\tLoss: 1.707475\n",
      "Train Epoch: 18 [9000/35339 (25%)]\tLoss: 1.679183\n",
      "Train Epoch: 18 [18000/35339 (51%)]\tLoss: 1.670630\n",
      "Train Epoch: 18 [27000/35339 (76%)]\tLoss: 1.744900\n",
      "\n",
      "Validation set: Average loss: 0.6408, Accuracy: 3425/3870 (89%)\n",
      "\n",
      "Train Epoch: 19 [0/35339 (0%)]\tLoss: 1.866055\n",
      "Train Epoch: 19 [9000/35339 (25%)]\tLoss: 1.608938\n",
      "Train Epoch: 19 [18000/35339 (51%)]\tLoss: 1.679095\n",
      "Train Epoch: 19 [27000/35339 (76%)]\tLoss: 1.830223\n",
      "\n",
      "Validation set: Average loss: 0.6230, Accuracy: 3433/3870 (89%)\n",
      "\n",
      "Train Epoch: 20 [0/35339 (0%)]\tLoss: 1.821737\n",
      "Train Epoch: 20 [9000/35339 (25%)]\tLoss: 1.507455\n",
      "Train Epoch: 20 [18000/35339 (51%)]\tLoss: 1.984671\n",
      "Train Epoch: 20 [27000/35339 (76%)]\tLoss: 1.910518\n",
      "\n",
      "Validation set: Average loss: 0.6293, Accuracy: 3432/3870 (89%)\n",
      "\n",
      "Train Epoch: 21 [0/35339 (0%)]\tLoss: 1.968019\n",
      "Train Epoch: 21 [9000/35339 (25%)]\tLoss: 1.862875\n",
      "Train Epoch: 21 [18000/35339 (51%)]\tLoss: 1.550447\n",
      "Train Epoch: 21 [27000/35339 (76%)]\tLoss: 1.960198\n",
      "\n",
      "Validation set: Average loss: 0.5897, Accuracy: 3446/3870 (89%)\n",
      "\n",
      "\n",
      "Saved model to model_21.pth. You can run `python evaluate.py model_21.pth` to generate the Kaggle formatted csv file\n",
      "Train Epoch: 22 [0/35339 (0%)]\tLoss: 1.746621\n",
      "Train Epoch: 22 [9000/35339 (25%)]\tLoss: 1.890172\n",
      "Train Epoch: 22 [18000/35339 (51%)]\tLoss: 2.022807\n",
      "Train Epoch: 22 [27000/35339 (76%)]\tLoss: 1.755109\n",
      "\n",
      "Validation set: Average loss: 0.5735, Accuracy: 3488/3870 (90%)\n",
      "\n",
      "\n",
      "Saved model to model_22.pth. You can run `python evaluate.py model_22.pth` to generate the Kaggle formatted csv file\n",
      "Train Epoch: 23 [0/35339 (0%)]\tLoss: 1.899368\n",
      "Train Epoch: 23 [9000/35339 (25%)]\tLoss: 1.923919\n",
      "Train Epoch: 23 [18000/35339 (51%)]\tLoss: 1.624706\n",
      "Train Epoch: 23 [27000/35339 (76%)]\tLoss: 1.571702\n",
      "\n",
      "Validation set: Average loss: 0.5941, Accuracy: 3436/3870 (89%)\n",
      "\n",
      "Train Epoch: 24 [0/35339 (0%)]\tLoss: 1.611248\n",
      "Train Epoch: 24 [9000/35339 (25%)]\tLoss: 1.817576\n",
      "Train Epoch: 24 [18000/35339 (51%)]\tLoss: 1.563493\n",
      "Train Epoch: 24 [27000/35339 (76%)]\tLoss: 2.134823\n",
      "\n",
      "Validation set: Average loss: 0.5752, Accuracy: 3473/3870 (90%)\n",
      "\n",
      "Train Epoch: 25 [0/35339 (0%)]\tLoss: 1.363985\n",
      "Train Epoch: 25 [9000/35339 (25%)]\tLoss: 2.013589\n",
      "Train Epoch: 25 [18000/35339 (51%)]\tLoss: 1.480542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 25 [27000/35339 (76%)]\tLoss: 1.674081\n",
      "\n",
      "Validation set: Average loss: 0.5709, Accuracy: 3473/3870 (90%)\n",
      "\n",
      "\n",
      "Saved model to model_25.pth. You can run `python evaluate.py model_25.pth` to generate the Kaggle formatted csv file\n",
      "Train Epoch: 26 [0/35339 (0%)]\tLoss: 1.871736\n",
      "Train Epoch: 26 [9000/35339 (25%)]\tLoss: 1.756385\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr , momentum=momentum, weight_decay=l2_norm, nesterov=True)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=decay)\n",
    "\n",
    "temp = 10\n",
    "for epoch in range(1, epochs):\n",
    "    train(epoch, train_loader)\n",
    "    val = validation()\n",
    "    if epoch % step :\n",
    "        scheduler.step()\n",
    "    if val < temp : \n",
    "        temp = val\n",
    "        model_file = 'model_' + str(epoch) + '.pth'\n",
    "        torch.save(model.state_dict(), model_file)\n",
    "        print('\\nSaved model to ' + model_file + '. You can run `python evaluate.py ' + model_file + '` to generate the Kaggle formatted csv file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
