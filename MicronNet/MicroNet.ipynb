{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "njs_2TyRN-MW",
    "outputId": "5157ceab-936c-48e1-d353-51a370a3cd1d"
   },
   "outputs": [],
   "source": [
    "# !git clone https://utkarshg99:55ee5e29de28047472734fd52fd9733206bfd64e@github.com/utkarshg99/bosch-tsr\n",
    "# !pip install -U albumentations\n",
    "# %cd bosch-tsr/MicronNet/\n",
    "# !apt install git-lfs\n",
    "# !git lfs pull\n",
    "# !tar -xf dataset.tar.gz\n",
    "# !tar -xf datasetaug.tar.gz\n",
    "# !rm -r DatasetAug/val_images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "K7INQIGoGvWC"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "nclasses = 43\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 1, kernel_size=1)\n",
    "        self.conv2 = nn.Conv2d(1, 29, kernel_size=5)\n",
    "        self.maxpool2 = nn.MaxPool2d(3, stride=2 , ceil_mode=True)\n",
    "        self.conv3 = nn.Conv2d(29, 59, kernel_size=3)\n",
    "        self.maxpool3 = nn.MaxPool2d(3, stride=2 , ceil_mode=True)\n",
    "        self.conv4 = nn.Conv2d(59, 74, kernel_size=3)\n",
    "        self.maxpool4 = nn.MaxPool2d(3, stride=2 , ceil_mode=True)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.conv3_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(1184, 300)\n",
    "        self.fc2 = nn.Linear(300, nclasses)\n",
    "        self.conv0_bn = nn.BatchNorm2d(3)\n",
    "        self.conv1_bn = nn.BatchNorm2d(1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(29)\n",
    "        self.conv3_bn = nn.BatchNorm2d(59)\n",
    "        self.conv4_bn = nn.BatchNorm2d(74)\n",
    "        self.dense1_bn = nn.BatchNorm1d(300)\n",
    "    def forward(self, x):\n",
    "        x =  F.relu(self.conv1_bn(self.conv1(self.conv0_bn(x))))\n",
    "        x = F.relu(self.conv2_bn(self.conv2(x)))\n",
    "        x = F.relu(self.conv3_bn(self.conv3( self.maxpool2(x))))\n",
    "        x = F.relu(self.conv4_bn(self.conv4( self.maxpool3(x))))\n",
    "        x = self.maxpool4(x)        \n",
    "        x = x.view(-1, 1184)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dense1_bn(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "g4DtnJg2KMlL"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "\n",
    "batch_size =50                                                                                                                                                                                     \n",
    "epochs = 10000                                                                                                                                                                                                                                                                                                                                                                                 \n",
    "seed = 1                                                                                                                                                                                           \n",
    "log_interval=180                                                                                                                                                                                   \n",
    "data = \"DatasetAug\"                                                                                                                                                                                                                                                                                                                                                                                          \n",
    "torch.manual_seed(1)                                                                                                                                                                               \n",
    "lr =0.007                                                                                                                                                                                          \n",
    "momentum = 0.8                                                                                                                                                                                     \n",
    "decay = 0.9                                                                                                                                                                                        \n",
    "step = 1000                                                                                                                                                                                        \n",
    "l2_norm = 0.00001  \n",
    "cuda = True\n",
    "resume = True\n",
    "# These may change as described in paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "WOb4JoD9KQtT"
   },
   "outputs": [],
   "source": [
    "class ADataset(Dataset):\n",
    "    def __init__(self, images_filepaths, transform=None):\n",
    "        self.images_filepaths = images_filepaths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_filepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.images_filepaths[idx]\n",
    "        image = cv2.imread(image_filepath)\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        label = int(os.path.normpath(image_filepath).split(os.sep)[-2])\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image=image)[\"image\"]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WyTXIm8IKS0b",
    "outputId": "8d10eead-9aeb-4704-f7b9-be04079ae2fa"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3951\ncuda:0\n"
     ]
    }
   ],
   "source": [
    "from data import initialize_data, data_transforms \n",
    "# initialize_data(data) # extracts the zip files, makes a validation set\n",
    "\n",
    "def generateImgFilePaths(base_path):\n",
    "    imgpths = []\n",
    "    for i in range(nclasses):\n",
    "        fldr=(\"/0000\" if i<10 else \"/000\")+str(i)\n",
    "        for path in os.listdir(base_path+fldr):\n",
    "            full_path = os.path.join(base_path+fldr, path)\n",
    "            if os.path.isfile(full_path) and not full_path.endswith(\".csv\"):\n",
    "                imgpths.append(full_path)\n",
    "    return imgpths\n",
    "\n",
    "# print(len(generateImgFilePaths(data + '/train_images')))\n",
    "\n",
    "fxc = ADataset(images_filepaths=generateImgFilePaths(data + '/train_images'), transform=data_transforms)\n",
    "train_loader = DataLoader(fxc, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "\n",
    "fxv = ADataset(images_filepaths=generateImgFilePaths(data + '/val_images'), transform=data_transforms)\n",
    "val_loader = DataLoader(fxv, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "print(len(generateImgFilePaths(data + '/val_images')))\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = Net()\n",
    "if  cuda: \n",
    "    model.to(device)\n",
    "\n",
    "if resume :\n",
    "    state_dict = torch.load(\"Top Models/Base43/model_114.pth\")\n",
    "    model.load_state_dict(state_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "P8mt40e0KVwI"
   },
   "outputs": [],
   "source": [
    "def validation():\n",
    "    model.eval()\n",
    "    validation_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in val_loader:\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        data=data.float()\n",
    "        data =data.to(device)\n",
    "        target =target.to(device)\n",
    "        output = model(data)\n",
    "        validation_loss += F.nll_loss(output, target, size_average=False).data.item() # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "    validation_loss /= len(val_loader.dataset)\n",
    "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        validation_loss, correct, len(val_loader.dataset),\n",
    "        100. * correct / len(val_loader.dataset)))\n",
    "    return validation_loss\n",
    "\n",
    "\n",
    "def train(epoch , train_loader):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        data=data.float()\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target).cuda()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, batch_idx * len(data), len(train_loader.dataset),100. * batch_idx / len(train_loader), loss.data.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e9aI_apKKYiG",
    "outputId": "d0c33399-b985-4f92-e5b9-9a8ff5eeb1fb"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-2-4582df93b7ac>:39: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n",
      "Train Epoch: 1 [0/35568 (0%)]\tLoss: 1.570131\n",
      "Train Epoch: 1 [9000/35568 (25%)]\tLoss: 1.763048\n",
      "Train Epoch: 1 [18000/35568 (51%)]\tLoss: 1.946194\n",
      "Train Epoch: 1 [27000/35568 (76%)]\tLoss: 1.648513\n",
      "C:\\Users\\Utkarsh\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "\n",
      "Validation set: Average loss: 0.6154, Accuracy: 3577/3951 (91%)\n",
      "\n",
      "\n",
      "Saved model to model_1.pth. You can run `python evaluate.py model_1.pth` to generate the Kaggle formatted csv file\n",
      "Train Epoch: 2 [0/35568 (0%)]\tLoss: 1.522452\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-89019ed3ac92>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-22cd399effb8>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epoch, train_loader)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mlog_interval\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \"\"\"\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr , momentum=momentum, weight_decay=l2_norm, nesterov=True)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=decay)\n",
    "\n",
    "temp = 10\n",
    "for epoch in range(1, epochs):\n",
    "    train(epoch, train_loader)\n",
    "    val = validation()\n",
    "    if epoch % step :\n",
    "        scheduler.step()\n",
    "    if val < temp : \n",
    "        temp = val\n",
    "        model_file = 'model_' + str(epoch) + '.pth'\n",
    "        torch.save(model.state_dict(), model_file)\n",
    "        print('\\nSaved model to ' + model_file + '. You can run `python evaluate.py ' + model_file + '` to generate the Kaggle formatted csv file')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MicroNet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}